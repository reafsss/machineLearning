{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"id\nage : 나이\nworkclass : 고용 형태\nfnlwgt : 사람 대표성을 나타내는 가중치 (final weight의 약자)\neducation : 교육 수준\neducation_num : 교육 수준 수치\nmarital_status: 결혼 상태\noccupation : 업종\nrelationship : 가족 관계\nrace : 인종\nsex : 성별\ncapital_gain : 양도 소득\ncapital_loss : 양도 손실\nhours_per_week : 주당 근무 시간\nnative_country : 국적\nincome : 수익 (예측해야 하는 값)\n>50K : 1\n<=50K : 0"},{"metadata":{},"cell_type":"markdown","source":"# 데이터 전처리"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings(action='ignore')\n\ntrain = pd.read_csv('/kaggle/input/kakr-4th-competition/train.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,j in enumerate(train):\n    print('-------------------------')    \n    print(j)\n    print('-------------------------')\n    print(train[j].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(8,4))\nsns.distplot(train['age'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_category","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(9,9))\ncorr = train.corr()\nsns.heatmap(corr, cmap='RdBu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum_up   = 0\nsum_down = 0\nfor i in train['income']:\n    if i == '>50K':\n        sum_up+=1\n    else :\n        sum_down+=1\n    \nprint(sum_up, sum_down, sum_up+sum_down)\n\ntrain['income'].value_counts().plot(kind='bar') \nplt.show()\n\n# from imblearn.over_sampling import SMOTE\n\n# smote = SMOTE(random_state=0)\n# X_train_over, y_train_over = smote.fit_sample(X_train, y_train)\n# print('SMOTE 적용 전 학습용 피처/레이블 데이터 세트:', X_train.shape, y_train.shape)\n# print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트:', X_train_over.shape, y_train_over.shape)\n# print('SMOTE 적용 후 레이블 값 분포:\\n', pd.Series(y_train_over).value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 데이터의 target 값이 불균형한 분포를 갖고있다고 판단됩니다. 따라서 오버 샘플링(Oversampling)으로 적절한 학습 데이터를 확보하겠습니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_category = [ col for col in train.columns if train[col].dtypes == \"object\"]\ntrain_category","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_category = list(set(train_category) - set(['id','income']))\ntrain_category","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in train_category: \n    train[col].value_counts().plot(kind='bar') \n    plt.title(col) \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_numerical = list(set(train.columns) - set(train_category) - set(['id','income']))\ntrain_numerical = np.sort(train_numerical)\ntrain_numerical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in train_numerical:\n    sns.distplot(train.loc[train[col].notnull(), col])\n    plt.title(col)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label = train['income']\n\ndel train['income']\n\ntest = pd.read_csv(\"/kaggle/input/kakr-4th-competition/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 라벨 값 인코딩\nlabel = label.map(lambda x: 1 if x == '>50K' else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* ID 컬럼은 행의 식별자로 필요 없는 컬럼이므로 삭제"},{"metadata":{"trusted":true},"cell_type":"code","source":"del train['id']\ndel test['id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_train = train.copy()\ntmp_test  = test.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 데이터 확인\n\n* .head(), .describe(), .info() 등의 함수로 데이터를 확인"},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.3 결측치 처리\n* 일반적인 결측치와 다르게 '?'로 표현되어 있는 값들은 해당 컬럼의 최빈값으로 결측치 처리를 진행\n* 범주형 변수의 경우 가장 간단하게 최빈값으로 결측치 처리를 할 수 있지만, 다른 컬럼을 필터링해서 결측치 처리를 할수도 있다."},{"metadata":{"trusted":true},"cell_type":"code","source":"has_na_columns = ['workclass', 'occupation', 'native_country']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(tmp_train[has_na_columns] == '?').sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in has_na_columns:\n    tmp_train.loc[train[c] == '?', c] = train[c].mode()[0]\n    tmp_test.loc[test[c]   == '?', c] = test[c].mode()[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(tmp_train[has_na_columns] == '?').sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.4 Log 변환\n* capital_gain 변수와 capital_loss 변수의 분포가 한쪽으로 치우친 형태이므로 Log 변환을 통해 분포의 형태를 조정"},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_train['capital_gain'].plot.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_train['log_capital_gain'] = train['capital_gain'].map(lambda x : np.log(x) if x != 0 else 0)\ntmp_test['log_capital_gain']  = test['capital_gain'].map(lambda x : np.log(x) if x != 0 else 0)\n\ntmp_train['log_capital_gain'].plot.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_test['log_capital_gain'].plot.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['capital_loss'].plot.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_train['log_capital_loss'] = train['capital_loss'].map(lambda x : np.log(x) if x != 0 else 0)\ntmp_test['log_capital_loss'] = test['capital_loss'].map(lambda x : np.log(x) if x != 0 else 0)\n\ntmp_train['log_capital_loss'].plot.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_train = tmp_train.drop(columns=['capital_loss','capital_gain'])\ntmp_test  = tmp_test.drop(columns=['capital_loss', 'capital_gain'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.5 데이터 쪼개기"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n\nX_train, X_test, y_train, y_test = train_test_split(tmp_train, label, test_size=0.3, random_state=2020, stratify=label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.reset_index(drop=True)\nX_test  = X_test.reset_index(drop=True)\ntmp_test  = tmp_test.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_columns = [c for c, t in zip(X_train.dtypes.index, X_train.dtypes) if t =='O']\nnum_columns = [c for c in X_train.dtypes.index if c not in cat_columns]\n\nprint('범주형 변수: \\n{0}\\n\\n 수지형 변수: \\n{1}\\n'.format(cat_columns, num_columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train[num_columns] = scaler.fit_transform(X_train[num_columns])\n\nX_test[num_columns] = scaler.transform(X_test[num_columns])\ntmp_test[num_columns]  = scaler.transform(tmp_test[num_columns])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_test.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 인덱스 초기화"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.6 스케일링\n* Scikit-learn 라이브러리에 있는 Standard Scaler를 사용해서 수치형 변수들의 표준화를 진행"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.6 인코딩\n* 범주형 변수를 수치형 변수로 인코딩 하겠습니다. 범주형 변수에는 Onehot Encoding을 적용합니다"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\ntmp_all = pd.concat([X_train, X_test, tmp_test])\n\nohe = OneHotEncoder(sparse=False)\nohe.fit(tmp_all[cat_columns])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe.categories_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe_columns=list()\nfor lst in ohe.categories_:\n    ohe_columns += lst.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train_cat = pd.DataFrame(ohe.transform(X_train[cat_columns]), columns=ohe_columns)\nnew_valid_cat = pd.DataFrame(ohe.transform(X_test[cat_columns]), columns=ohe_columns)\nnew_test_cat  = pd.DataFrame(ohe.transform(tmp_test[cat_columns]), columns=ohe_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train_cat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = pd.concat([X_train, new_train_cat], axis=1)\nX_test = pd.concat([X_test, new_valid_cat], axis=1)\ntmp_test  = pd.concat([tmp_test, new_test_cat], axis=1)\n\n# 기존 범수형 변수 제거\nX_train = X_train.drop(columns=cat_columns)\nX_test = X_test.drop(columns=cat_columns)\ntmp_test  = tmp_test.drop(columns=cat_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_y_train = y_train\ntmp_y_test = y_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Scikit-Learn 분류 모델 사용\n* Scikit-Learn의 기본 분류 모델을 사용해보겠습니다. 각 모델의 평가 메트릭은 대회 평가 메트릭인 f1_score를 사용합니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\nfrom sklearn.metrics import f1_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.1 로지스틱 회귀 모델"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression()\n\nlr.fit(X_train, tmp_y_train)\n\ny_pred = lr.predict(X_test)\n\nprint('Logistic Regression F1 Score: {0:.10f}'.format(f1_score(tmp_y_test, y_pred, average='micro')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2 서포트 벡터 머신(rbf 커널)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# svc = SVC()\n\n# svc.fit(X_train, tmp_y_train)\n\n# y_pred = svc.predict(X_test)\n\n# print('Support Vector Machine F1 Score: {0:.10f}'.format(f1_score(tmp_y_test, y_pred, average='micro')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.3 랜덤 포레스트"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier()\n\nrf.fit(X_train, tmp_y_train)\n\ny_pred = rf.predict(X_test)\n\nprint('RandomForest F1 Score: {0:.10f}'.format(f1_score(tmp_y_test, y_pred, average='micro')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.4 XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBClassifier(tree_method='gpu_hist')\n\nxgb.fit(X_train, tmp_y_train)\n\ny_pred = xgb.predict(X_test)\n\nprint('XGBoost F1 Score: {0:.10f}'.format(f1_score(tmp_y_test, y_pred, average='micro')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.5 LightGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb = LGBMClassifier(tree_method='gpu_hist')\n\nlgb.fit(X_train, tmp_y_train)\n\ny_pred = lgb.predict(X_test)\n\nprint('LightGBM F1 Score: {0:.10f}'.format(f1_score(tmp_y_test, y_pred, average='micro')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. k-Fold Cross Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(x_train, x_valid, x_test):\n    tmp_x_train = x_train.copy()\n    tmp_x_valid = x_valid.copy()\n    tmp_x_test  = x_test.copy()\n    \n    tmp_x_train = tmp_x_train.reset_index(drop=True)\n    tmp_x_valid = tmp_x_valid.reset_index(drop=True)\n    tmp_x_test  = tmp_x_test.reset_index(drop=True)\n    \n    for c in has_na_columns:\n        tmp_x_train.loc[tmp_x_train[c] == '?', c] = tmp_x_train[c].mode()[0]\n        tmp_x_valid.loc[tmp_x_valid[c] == '?', c] = tmp_x_valid[c].mode()[0]\n        tmp_x_test.loc[tmp_x_test[c]   == '?', c] = tmp_x_test[c].mode()[0]\n    \n    tmp_x_train['log_capital_loss'] = tmp_x_train['capital_loss'].map(lambda x : np.log(x) if x != 0 else 0)\n    tmp_x_valid['log_capital_loss'] = tmp_x_valid['capital_loss'].map(lambda x : np.log(x) if x != 0 else 0)\n    tmp_x_test['log_capital_loss'] = tmp_x_test['capital_loss'].map(lambda x : np.log(x) if x != 0 else 0)\n    tmp_x_train['log_capital_gain'] = tmp_x_train['capital_gain'].map(lambda x : np.log(x) if x != 0 else 0)\n    tmp_x_valid['log_capital_gain'] = tmp_x_valid['capital_gain'].map(lambda x : np.log(x) if x != 0 else 0)\n    tmp_x_test['log_capital_gain'] = tmp_x_test['capital_gain'].map(lambda x : np.log(x) if x != 0 else 0)\n    \n    tmp_x_train = tmp_x_train.drop(columns=['capital_loss', 'capital_gain'])\n    tmp_x_valid = tmp_x_valid.drop(columns=['capital_loss', 'capital_gain'])\n    tmp_x_test  = tmp_x_test.drop(columns=['capital_loss', 'capital_gain'])\n    \n    scaler = StandardScaler()\n    tmp_x_train[num_columns] = scaler.fit_transform(tmp_x_train[num_columns])\n    tmp_x_valid[num_columns] = scaler.transform(tmp_x_valid[num_columns])\n    tmp_x_test[num_columns]  = scaler.transform(tmp_x_test[num_columns])\n    \n    tmp_all = pd.concat([tmp_x_train, tmp_x_valid, tmp_x_test])\n\n    ohe = OneHotEncoder(sparse=False)\n    ohe.fit(tmp_all[cat_columns])\n    \n    ohe_columns = list()\n    for lst in ohe.categories_:\n        ohe_columns += lst.tolist()\n    \n    tmp_train_cat = pd.DataFrame(ohe.transform(tmp_x_train[cat_columns]), columns=ohe_columns)\n    tmp_valid_cat = pd.DataFrame(ohe.transform(tmp_x_valid[cat_columns]), columns=ohe_columns)\n    tmp_test_cat  = pd.DataFrame(ohe.transform(tmp_x_test[cat_columns]), columns=ohe_columns)\n    \n    tmp_x_train = pd.concat([tmp_x_train, tmp_train_cat], axis=1)\n    tmp_x_valid = pd.concat([tmp_x_valid, tmp_valid_cat], axis=1)\n    tmp_x_test = pd.concat([tmp_x_test, tmp_test_cat], axis=1)\n\n    tmp_x_train = tmp_x_train.drop(columns=cat_columns)\n    tmp_x_valid = tmp_x_valid.drop(columns=cat_columns)\n    tmp_x_test = tmp_x_test.drop(columns=cat_columns)\n    \n    return tmp_x_train.values, tmp_x_valid.values, tmp_x_test.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def xgb_f1(y, t, threshold=0.5):\n    t = t.get_label()\n    y_bin = (y > threshold).astype(int) \n    return 'f1', f1_score(t, y_bin, average='micro')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\nn_splits = 5\nskf = StratifiedKFold(n_splits=n_splits, shuffle = True, random_state=2020)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# val_scores = list()\n# oof_pred = np.zeros((test.shape[0],))\n\n# for i, (trn_idx, val_idx) in enumerate(skf.split(train, label)):\n#     x_train, y_train = train.iloc[trn_idx, :], label[trn_idx]\n#     x_valid, y_valid = train.iloc[val_idx, :], label[val_idx]\n    \n#     # 전처리\n#     x_train, x_valid, x_test = preprocess(x_train, x_valid, test)\n    \n#     # 모델 정의\n#     clf = XGBClassifier(tree_method='gpu_hist')\n    \n#     # 모델 학습\n#     clf.fit(x_train, y_train,\n#             eval_set = [[x_valid, y_valid]], \n#             eval_metric = xgb_f1,        \n#             early_stopping_rounds = 100,\n#             verbose = 100,  )\n\n#     # 훈련, 검증 데이터 F1 Score 확인\n#     trn_f1_score = f1_score(y_train, clf.predict(x_train), average='micro')\n#     val_f1_score = f1_score(y_valid, clf.predict(x_valid), average='micro')\n#     print('{} Fold, train f1_score : {:.4f}4, validation f1_score : {:.4f}\\n'.format(i, trn_f1_score, val_f1_score))\n    \n#     val_scores.append(val_f1_score)\n    \n# # 교차 검증 F1 Score 평균 계산하기\n# print('Cross Validation Score : {:.4f}'.format(np.mean(val_scores)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# OOF(Out-Of-Fold) 앙상블\n* k-Fold를 활용해 모델 검증및 각 폴드의 결과를 앙상블하는 OOF 앙상블"},{"metadata":{"trusted":true},"cell_type":"code","source":"# val_scores = list()\n# oof_pred = np.zeros((test.shape[0], )) #\n\n# for i, (trn_idx, val_idx) in enumerate(skf.split(train, label)):\n#     x_train, y_train = train.iloc[trn_idx, :], label[trn_idx]\n#     x_valid, y_valid = train.iloc[val_idx, :], label[val_idx]\n    \n#     # 전처리\n#     x_train, x_valid, x_test = preprocess(x_train, x_valid, test)\n    \n#     # 모델 정의\n#     clf = XGBClassifier(tree_method='gpu_hist')\n    \n#     # 모델 학습\n#     clf.fit(x_train, y_train,\n#             eval_set = [[x_valid, y_valid]], \n#             eval_metric = xgb_f1,        \n#             early_stopping_rounds = 100,\n#             verbose = 100,  )\n\n#     # 훈련, 검증 데이터 F1 Score 확인\n#     trn_f1_score = f1_score(y_train, clf.predict(x_train), average='micro')\n#     val_f1_score = f1_score(y_valid, clf.predict(x_valid), average='micro')\n#     print('{} Fold, train f1_score : {:.4f}4, validation f1_score : {:.4f}\\n'.format(i, trn_f1_score, val_f1_score))\n    \n#     val_scores.append(val_f1_score)\n    \n#     oof_pred += clf.predict_proba(x_test)[: , 1] / n_splits #\n    \n\n# # 교차 검증 F1 Score 평균 계산하기\n# print('Cross Validation Score : {:.4f}'.format(np.mean(val_scores)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Stacking 앙상블"},{"metadata":{"trusted":true},"cell_type":"code","source":"val_scores = list()\n\nnew_x_train_list = [np.zeros((train.shape[0], 1)) for _ in range(4)]\nnew_x_test_list  = [np.zeros((test.shape[0], 1)) for _ in range(4)]\n\nfor i, (trn_idx, val_idx) in enumerate(skf.split(train, label)):\n    print(f\"Fold {i} Start\")\n    x_train, y_train = train.iloc[trn_idx, :], label[trn_idx]\n    x_valid, y_valid = train.iloc[val_idx, :], label[val_idx]\n    \n    # 전처리\n    x_train, x_valid, x_test = preprocess(x_train, x_valid, test)\n    \n    # 모델 정의\n    clfs = [LogisticRegression(), \n            RandomForestClassifier(), \n            XGBClassifier(tree_method='gpu_hist'), \n            LGBMClassifier(tree_method='gpu_hist')]\n    \n    for model_idx, clf in enumerate(clfs):\n        clf.fit(x_train, y_train)\n        \n        new_x_train_list[model_idx][val_idx, :] = clf.predict_proba(x_valid)[:, 1].reshape(-1, 1)\n        new_x_test_list[model_idx][:] += clf.predict_proba(x_test)[:, 1].reshape(-1, 1) / n_splits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_x_train_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_x_test_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train = pd.DataFrame(np.concatenate(new_x_train_list, axis=1), columns=None)\nnew_label = label\nnew_test = pd.DataFrame(np.concatenate(new_x_test_list, axis=1), columns=None)\n\nnew_train.shape, new_label.shape, new_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_scores = list()\noof_pred = np.zeros((test.shape[0], ))\n\nfor i, (trn_idx, val_idx) in enumerate(skf.split(new_train, new_label)):\n    x_train, y_train = new_train.iloc[trn_idx, :], new_label[trn_idx]\n    x_valid, y_valid = new_train.iloc[val_idx, :], new_label[val_idx]\n    \n    # 전처리\n    scaler = StandardScaler()\n    x_train = scaler.fit_transform(x_train)\n    x_valid = scaler.transform(x_valid)\n    x_test  = scaler.transform(new_test)\n    \n    # 모델 정의\n    clf = XGBClassifier(tree_method='gpu_hist')\n    \n    # 모델 학습\n    clf.fit(x_train, y_train,\n            eval_set = [[x_valid, y_valid]], \n            eval_metric = xgb_f1,        \n            early_stopping_rounds = 100,\n            verbose = 100,  )\n\n    # 훈련, 검증 데이터 F1 Score 확인\n    trn_f1_score = f1_score(y_train, clf.predict(x_train), average='micro')\n    val_f1_score = f1_score(y_valid, clf.predict(x_valid), average='micro')\n    print('{} Fold, train f1_score : {:.4f}4, validation f1_score : {:.4f}\\n'.format(i, trn_f1_score, val_f1_score))\n    \n    val_scores.append(val_f1_score)\n    \n    oof_pred += clf.predict_proba(x_test)[:, 1] / n_splits\n    \n\n# 교차 검증 F1 Score 평균 계산하기\nprint('Cross Validation Score : {:.4f}'.format(np.mean(val_scores)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. 결과 만들기"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.listdir(\"/kaggle/input/kakr-4th-competition/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = pd.read_csv(\"/kaggle/input/kakr-4th-competition/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit.loc[:, 'prediction'] = (oof_pred > 0.5).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit.to_csv('stacking_submit.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}